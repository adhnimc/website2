[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Github    LinkedIn  \n\nWelcome to my personal website! I’m Adhni Mulachela, originally from Indonesia. I’m currently pursuing a Master of Business Analytics at Monash University.\nI have experience working in the tech and logistics industry, where I’ve developed skills that complement my academic pursuits. You can view my resume in the top right corner of the page for more professional details about me. Here, you’ll also find a mix of my assignments under the tag “assignment” and some of my thoughts on various topics under the tag “dumps.” Feel free to explore my work and professional profiles below!"
  },
  {
    "objectID": "posts/Article/Article.html",
    "href": "posts/Article/Article.html",
    "title": "Rethinking Olympic Strategies",
    "section": "",
    "text": "Rizky Juniansyah winning Indonesia’s first ever Weightlifting Gold Medal in Olympics History"
  },
  {
    "objectID": "posts/Article/Article.html#rethinking-olympic-strategies-the-correlation-between-number-of-athletes-and-medal-counts",
    "href": "posts/Article/Article.html#rethinking-olympic-strategies-the-correlation-between-number-of-athletes-and-medal-counts",
    "title": "Rethinking Olympic Strategies",
    "section": "Rethinking Olympic Strategies: The Correlation Between Number of Athletes and Medal Counts",
    "text": "Rethinking Olympic Strategies: The Correlation Between Number of Athletes and Medal Counts\n\nProblem Description\nThis report addresses the relationship between the number of athletes a country sends to the Olympics and its medal count. The analysis explores whether countries should shift their focus from rewarding medal-winning athletes through cash incentives to a more long-term strategy of increasing athlete participation, which could result in higher medal tallies.\n\n\nData Description\nThe data used in this analysis was sourced from the 2024 Summer Olympics medal table (Wikipedia, 2024). It includes variables for the total number of athletes a country sends, the number of gold, silver, and bronze medals won, and the overall medal count.\nThe dataset includes the following variables: Country, representing the name of each country; Athletes, indicating the number of athletes sent to the Olympics by each country; and Gold, Silver, and Bronze, which denote the number of medals won in each respective category. Additionally, the dataset includes Total_Medals, representing the total number of medals won by each country.\nData Cleaning Steps:\n\n\nFiltered the data to include only countries with at least one medal.\n\n\nCalculated the ratio of athletes per medal.\n\n\nRemoved team sports from the analysis to avoid skewing results due to larger teams.\n\n\nFilled missing values for some countries’ athlete counts using historical data.\n\n\nAnalysis The relationship between the number of athletes and total medal counts was analyzed through both a table and a plot. The table provides a clear overview of the countries with their corresponding athlete counts and medals, while the plot visualizes the positive correlation between athletes and medal counts.\n\n\n\n\nTable 1: Countries, Athletes, and Medal Counts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nNumber_of_Athletes\nGold\nSilver\nBronze\nTotal\nRatio_Athletes_Per_Medal\nratio\n\n\n\n\n41\nUnited States\n592\n40\n44\n42\n126\n4.698413\n0.2128378\n\n\n7\nChina\n388\n40\n27\n24\n91\n4.263736\n0.2345361\n\n\n14\nGreat Britain\n327\n14\n22\n29\n65\n5.030769\n0.1987768\n\n\n11\nFrance\n573\n16\n26\n22\n64\n8.953125\n0.1116928\n\n\n1\nAustralia\n461\n18\n19\n16\n53\n8.698113\n0.1149675\n\n\n23\nJapan\n403\n20\n12\n13\n45\n8.955556\n0.1116625\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\nThe correlation between the number of athletes and total medals is apparent in both Table 1 and Figure 1. Countries with more athletes generally win more medals, indicating that investing in a larger pool of athletes can lead to better Olympic performance.\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 2 further reinforces the idea that countries with fewer athletes per medal (i.e., a more efficient conversion of athletes into medals) are rare. Most countries see a significant correlation between the number of athletes sent and the number of medals won.\n\n\nConclusion\nThis analysis demonstrates that countries should focus on developing and sending more athletes to the Olympics rather than just incentivizing current medal winners. By broadening participation and investing in youth development, countries are likely to see improved long-term success in terms of medal counts. This strategy supports the idea that Olympic success is more attainable when countries expand their athlete base rather than focusing exclusively on a few high-profile athletes (CNBC, 2024).\n\n\nReference\n\nWikipedia. (2024). 2024 Summer Olympics medal table.\nCNBC. (2024). Here’s how much athletes at the Paris Olympics earn for winning medals. Retrieved from CNBC\nR Core Team. (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org\nWickham, H., & Henry, L. (2024). rvest: Easily web scrape data. https://cran.r-project.org/package=rvest\nWickham, H. (2024). dplyr: A grammar of data manipulation. https://cran.r-project.org/package=dplyr\nWickham, H. (2024). stringr: Simple, consistent string manipulation. https://cran.r-project.org/package=stringr\nWickham, H. (2024). ggplot2: Create elegant data visualisations. https://cran.r-project.org/package=ggplot2\nOpenAI. (2024). ChatGPT: Language model for conversational AI. https://www.openai.com/chatgpt"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Blog/Blog.html",
    "href": "posts/Blog/Blog.html",
    "title": "TEST",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adhni Mulachela",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nPublic Transport Transit Time Analysis\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nWhich Australian city has the cleanest air?\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nAFL Grand Final\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nnycflights13\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nIMDB Ratings - Indonesian Movies\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nBerlin Marathon 2019\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nFIFA Ranking by GDP per Capita\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nRethinking Olympic Strategies\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\nBerlin Marathon 2018\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\n\n\n\n\n\n\n2024 Pilpres vs Pileg Party Coalition Vote Percentages\n\n\n\n\n\n\nArticle\n\n\n\n\n\n\n\n\n\nAdhni Mulachela\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/afl/AFL2.html",
    "href": "posts/afl/AFL2.html",
    "title": "AFL Grand Final",
    "section": "",
    "text": "A Story of Triumph: The AFL Grand Finals (2015–2024)\nOnce upon a time in the vibrant world of Australian Rules Football (AFL), a fierce rivalry unfolded over a decade, showcasing the dedication and spirit of teams that aimed for glory in the Grand Final. From 2015 to 2024, teams like the Brisbane Lions, Sydney Swans, and Richmond Tigers battled for the prestigious title, creating unforgettable moments that fans would cherish forever.\n\n\nThe Teams and Their Journeys\nIn this tale, each year brought new champions and challenges. The Brisbane Lions roared into action, claiming victories with impressive scores, while the Sydney Swans showcased resilience, always ready to reclaim their spot in the limelight. The Collingwood Magpies and Geelong Cats also left their mark, fighting hard to secure their place in the hearts of fans.\n\n\nScoreboard Chronicles\nEach year from 2015 to 2024 was marked by thrilling matchups, where the scores told the story of triumph and heartbreak. The data revealed the highs and lows, with the winners proudly displaying their logos, signifying their hard-fought victories.\n\n\nA Visual Representation of Glory\nTo capture the essence of these battles, a stunning visualization was created. A scatter plot illustrated the fierce competition, showing the winners and losers side by side. Each logo represented a team’s journey, while translucent bars indicated the score differences, revealing the intensity of each matchup.\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nThe Legacy of the Winners\nFinally, a table emerged, showcasing the champions of each year. This table celebrated their victories, with logos adding a visual flair, reminding fans of the memorable moments that unfolded on the field.\n\n\n\n\n\n\n\n\nConclusion\nAnd so, the story of the AFL Grand Finals from 2015 to 2024 was etched in the memories of fans and players alike. Each score, each logo, and each game contributed to a rich tapestry of sporting history, celebrating the spirit of competition and the thrill of victory. As the years go by, these moments will continue to inspire future generations of players and fans in the exhilarating world of AFL."
  },
  {
    "objectID": "posts/afl/dummyscores.html",
    "href": "posts/afl/dummyscores.html",
    "title": "Dummyscores",
    "section": "",
    "text": "# Load necessary library\nset.seed(123)  # Set seed for reproducibility\n\n# Teams list\nteams &lt;- c(\"Collingwood Magpies\", \"Brisbane Lions\", \"Port Adelaide\", \"Melbourne Demons\",\n           \"Carlton FC\", \"St Kilda FC\", \"Sydney Swans\", \"Western Bulldogs\", \"Richmond Tigers\",\n           \"Gold Coast Suns\", \"Essendon FC\", \"Fremantle FC\", \"Hawthorn Hawks\",\n           \"North Melbourne\", \"West Coast Eagles\")\n\n# Function to generate dummy data\ngenerate_afl_data &lt;- function(year) {\n  win_count &lt;- sample(2:18, 15, replace = TRUE)  # Random win count between 2 and 18\n  lose_count &lt;- 22 - win_count  # Total games played is 22, so lose count is calculated\n  tie_count &lt;- sample(0:1, 15, replace = TRUE)  # Random tie count (0 or 1)\n  points &lt;- win_count * 4  # Points based on win count (4 points per win)\n  \n  data.frame(\n    Team = teams,\n    Season = year,\n    Points = points,\n    Win_Count = win_count,\n    Lose_Count = lose_count,\n    Tie_Count = tie_count\n  )\n}\n\n# Generate data for years 2024 to 2028\nafl_data_2024 &lt;- generate_afl_data(2024)\nafl_data_2025 &lt;- generate_afl_data(2025)\nafl_data_2026 &lt;- generate_afl_data(2026)\nafl_data_2027 &lt;- generate_afl_data(2027)\nafl_data_2028 &lt;- generate_afl_data(2028)\n\n# Combine all the data\nafl_dummy_data &lt;- rbind(afl_data_2024, afl_data_2025, afl_data_2026, afl_data_2027, afl_data_2028)\n\n# Display the generated data\nprint(afl_dummy_data)\n\n                  Team Season Points Win_Count Lose_Count Tie_Count\n1  Collingwood Magpies   2024     64        16          6         1\n2       Brisbane Lions   2024     60        15          7         0\n3        Port Adelaide   2024     16         4         18         0\n4     Melbourne Demons   2024     44        11         11         0\n5           Carlton FC   2024     48        12         10         0\n6          St Kilda FC   2024     24         6         16         1\n7         Sydney Swans   2024     60        15          7         0\n8     Western Bulldogs   2024     24         6         16         1\n9      Richmond Tigers   2024     40        10         12         1\n10     Gold Coast Suns   2024     16         4         18         0\n11         Essendon FC   2024     36         9         13         0\n12        Fremantle FC   2024     32         8         14         0\n13      Hawthorn Hawks   2024     44        11         11         0\n14     North Melbourne   2024     40        10         12         1\n15   West Coast Eagles   2024     20         5         17         0\n16 Collingwood Magpies   2025     32         8         14         1\n17      Brisbane Lions   2025     28         7         15         1\n18       Port Adelaide   2025     12         3         19         1\n19    Melbourne Demons   2025     24         6         16         0\n20          Carlton FC   2025     36         9         13         0\n21         St Kilda FC   2025     52        13          9         1\n22        Sydney Swans   2025     56        14          8         0\n23    Western Bulldogs   2025      8         2         20         1\n24     Richmond Tigers   2025     28         7         15         1\n25     Gold Coast Suns   2025     64        16          6         0\n26         Essendon FC   2025     40        10         12         1\n27        Fremantle FC   2025     64        16          6         1\n28      Hawthorn Hawks   2025     68        17          5         0\n29     North Melbourne   2025     28         7         15         0\n30   West Coast Eagles   2025     48        12         10         1\n31 Collingwood Magpies   2026     60        15          7         1\n32      Brisbane Lions   2026     16         4         18         1\n33       Port Adelaide   2026     36         9         13         1\n34    Melbourne Demons   2026     68        17          5         1\n35          Carlton FC   2026     52        13          9         0\n36         St Kilda FC   2026     60        15          7         1\n37        Sydney Swans   2026     16         4         18         1\n38    Western Bulldogs   2026     60        15          7         1\n39     Richmond Tigers   2026     32         8         14         0\n40     Gold Coast Suns   2026     16         4         18         1\n41         Essendon FC   2026     64        16          6         1\n42        Fremantle FC   2026     24         6         16         1\n43      Hawthorn Hawks   2026     36         9         13         0\n44     North Melbourne   2026     44        11         11         1\n45   West Coast Eagles   2026     44        11         11         1\n46 Collingwood Magpies   2027     64        16          6         1\n47      Brisbane Lions   2027     72        18          4         1\n48       Port Adelaide   2027     48        12         10         0\n49    Melbourne Demons   2027     32         8         14         0\n50          Carlton FC   2027     64        16          6         0\n51         St Kilda FC   2027     28         7         15         0\n52        Sydney Swans   2027     60        15          7         1\n53    Western Bulldogs   2027     32         8         14         1\n54     Richmond Tigers   2027     44        11         11         0\n55     Gold Coast Suns   2027     24         6         16         0\n56         Essendon FC   2027     28         7         15         1\n57        Fremantle FC   2027     68        17          5         1\n58      Hawthorn Hawks   2027     48        12         10         0\n59     North Melbourne   2027     20         5         17         0\n60   West Coast Eagles   2027     52        13          9         1\n61 Collingwood Magpies   2028     64        16          6         0\n62      Brisbane Lions   2028     32         8         14         0\n63       Port Adelaide   2028     20         5         17         1\n64    Melbourne Demons   2028      8         2         20         1\n65          Carlton FC   2028     36         9         13         0\n66         St Kilda FC   2028     68        17          5         0\n67        Sydney Swans   2028     48        12         10         1\n68    Western Bulldogs   2028     68        17          5         0\n69     Richmond Tigers   2028     36         9         13         0\n70     Gold Coast Suns   2028     16         4         18         1\n71         Essendon FC   2028     20         5         17         1\n72        Fremantle FC   2028     52        13          9         0\n73      Hawthorn Hawks   2028     72        18          4         1\n74     North Melbourne   2028     44        11         11         1\n75   West Coast Eagles   2028     48        12         10         1\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(ggimage)\nlibrary(grid)  # For rasterGrob to add the image as background\nlibrary(png)   # For reading PNG images\n\n\n# Define a function to create the plot for a given team\ncreate_team_plot &lt;- function(team_name) {\n  # Filter the team's data from the dataset\n  team_data &lt;- afl_dummy_data[afl_dummy_data$Team == team_name, ]\n  \n  # Create a dot plot with curved black lines for the team's points across the years\n  p &lt;- ggplot() +\n    # Background rectangle\n    geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf), \n              fill = \"lightgrey\", alpha = 0.2) +  # Light grey background with transparency\n    \n    # Dots for points\n    geom_point(data = team_data, aes(x = as.factor(Season), y = Points, group = 1), size = 5, color = \"blue\") +\n    \n    # Curved black line connecting the dots\n    geom_smooth(data = team_data, aes(x = as.factor(Season), y = Points, group = 1), \n                method = \"loess\", se = FALSE, color = \"black\", linetype = \"solid\", size = 1.2) +\n    \n    # Text labels for points\n    geom_text(data = team_data, aes(x = as.factor(Season), y = Points, label = Points), \n              vjust = -1.5, size = 5, color = \"black\") +\n    \n    # Labels and title\n    labs(title = paste(team_name, \"Points (2024–2028)\"),\n         x = \"Season\",\n         y = \"Points\") +\n    \n    # Clean theme\n    theme_minimal(base_size = 16) +  \n    theme(\n      plot.title = element_text(face = \"bold\", size = 20, hjust = 0.5),\n      axis.title = element_text(face = \"bold\", size = 16),\n      axis.text = element_text(size = 14)\n    )\n  \n  return(p)\n}\n\n# List of all teams\nall_teams &lt;- unique(afl_dummy_data$Team)\n\n# Create a list to store plots\nteam_plots &lt;- list()\n\n# Generate plots for all teams\nfor (team in all_teams) {\n  team_plots[[team]] &lt;- create_team_plot(team)\n  \n  # Display the plots (optional)\n  print(team_plots[[team]])\n  \n  # Optionally save the plots to files\n  ggsave(paste0(team, \"_Points.png\"), plot = team_plots[[team]], width = 12, height = 8, dpi = 300)\n}\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.98\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2.02\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.0804"
  },
  {
    "objectID": "posts/afl/Afl.html",
    "href": "posts/afl/Afl.html",
    "title": "AFL",
    "section": "",
    "text": "# Load necessary library\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\n\n# Create a data frame with the given data\nafl_data &lt;- data.frame(\n  Year = c(2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014),\n  Winner = c(\"Brisbane Lions\", \"Collingwood Magpies\", \"Geelong Cats\", \"Melbourne Demons\", \n             \"Richmond Tigers\", \"Richmond Tigers\", \"West Coast Eagles\", \"Richmond Tigers\", \n             \"Western Bulldogs\", \"Hawthorn Hawks\", \"Hawthorn Hawks\"),\n  Winner_Score = c(120, 90, 133, 140, 81, 114, 79, 108, 89, 107, 137),\n  Loser = c(\"Sydney Swans\", \"Brisbane Lions\", \"Sydney Swans\", \"Western Bulldogs\", \n            \"Geelong Cats\", \"Greater Western Sydney\", \"Collingwood Magpies\", \n            \"Adelaide Crows\", \"Sydney Swans\", \"West Coast Eagles\", \"Sydney Swans\"),\n  Loser_Score = c(60, 86, 52, 66, 50, 25, 74, 60, 67, 61, 74)\n)\n\n# Add the 'Difference' column\nafl_data &lt;- afl_data %&gt;%\n  mutate(Difference = Winner_Score - Loser_Score)\n\n# Add the 'Difference/WinnerScore' column\nafl_data &lt;- afl_data %&gt;%\n  mutate(Diff_Winner_Score_Ratio = Difference / Winner_Score)\n\n# Display the updated data frame\nafl_data\n\n   Year              Winner Winner_Score                  Loser Loser_Score\n1  2024      Brisbane Lions          120           Sydney Swans          60\n2  2023 Collingwood Magpies           90         Brisbane Lions          86\n3  2022        Geelong Cats          133           Sydney Swans          52\n4  2021    Melbourne Demons          140       Western Bulldogs          66\n5  2020     Richmond Tigers           81           Geelong Cats          50\n6  2019     Richmond Tigers          114 Greater Western Sydney          25\n7  2018   West Coast Eagles           79    Collingwood Magpies          74\n8  2017     Richmond Tigers          108         Adelaide Crows          60\n9  2016    Western Bulldogs           89           Sydney Swans          67\n10 2015      Hawthorn Hawks          107      West Coast Eagles          61\n11 2014      Hawthorn Hawks          137           Sydney Swans          74\n   Difference Diff_Winner_Score_Ratio\n1          60              0.50000000\n2           4              0.04444444\n3          81              0.60902256\n4          74              0.52857143\n5          31              0.38271605\n6          89              0.78070175\n7           5              0.06329114\n8          48              0.44444444\n9          22              0.24719101\n10         46              0.42990654\n11         63              0.45985401\n\n\n\n# Reshape the data to long format but only for Winner_Score and Loser_Score\nafl_scores_long &lt;- afl_data %&gt;%\n  select(Year, Winner_Score, Loser_Score) %&gt;%\n  pivot_longer(cols = c(Winner_Score, Loser_Score),\n               names_to = \"Score_Type\",\n               values_to = \"Score\")\n\n# Create the line plot with both Winner and Loser scores\n# Create the plot with both Winner and Loser scores, joined by a line within each year\n\n\nggplot(afl_data, aes(x = as.factor(Year))) +\n  geom_point(aes(y = Winner_Score, color = \"Winner Score\"), size = 5) +\n  geom_point(aes(y = Loser_Score, color = \"Loser Score\"), size = 5) +\n  geom_segment(aes(x = as.factor(Year), xend = as.factor(Year), y = Winner_Score, yend = Loser_Score), \n               color = \"black\", linetype = \"dashed\", size = .2) +\n  labs(title = \"AFL Grand Final: Winner vs Loser Scores Over the Last 10 Years\",\n       x = \"Year\",\n       y = \"Score\",\n       color = \"Score Type\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "posts/nyflights13/Article.html",
    "href": "posts/nyflights13/Article.html",
    "title": "nycflights13",
    "section": "",
    "text": "# Load the libraries\nlibrary(nycflights13)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(leaflet)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nflights &lt;- flights\n\n\n# Step 1: Join airline names and rename to avoid conflicts\nflights_subset &lt;- flights %&gt;%\n  filter(\n    !dest %in% c(\"HNL\", \"ANC\"),  # Exclude Honolulu and Anchorage\n    carrier %in% c(\"AA\", \"DL\", \"UA\", \"B6\", \"WN\")  # Keep only selected airlines\n  ) %&gt;%\n  left_join(airlines, by = c(\"carrier\" = \"carrier\")) %&gt;%\n  rename(airline_name = name)  # Rename airline name column to avoid conflict with airport names\n\n# Step 2: Summarize flights by destination and airline\nflights_summary &lt;- flights_subset %&gt;%\n  group_by(dest, airline_name) %&gt;%\n  summarise(total_flights = n(), .groups = \"drop\") %&gt;%\n  group_by(dest) %&gt;%\n  mutate(\n    dominant_airline_name = airline_name[which.max(total_flights)],  # Determine dominant airline by name\n    total_flights = sum(total_flights),  # Total flights to the destination\n    avg_flights_per_day = round(total_flights / 365, 1)  # Average flights per day (1 decimal place)\n  ) %&gt;%\n  filter(total_flights &gt;= 365)  # Keep destinations with at least 2000 flights\n\n# Step 3: Add geolocation data for destinations using the airports dataset\nflights_map_data &lt;- flights_summary %&gt;%\n  left_join(airports, by = c(\"dest\" = \"faa\"))  # Join with airports dataset\n\n# Step 4: Add LGA coordinates as the origin point for all lines\nlga_coordinates &lt;- airports %&gt;%\n  filter(faa == \"LGA\") %&gt;%\n  select(lat, lon) %&gt;%\n  rename(lga_lat = lat, lga_lon = lon)\n\n# Ensure LGA coordinates and hover text are added to flights_map_data\nflights_map_data &lt;- flights_map_data %&gt;%\n  mutate(\n    lga_lat = lga_coordinates$lga_lat[1],  # Add LGA latitude\n    lga_lon = lga_coordinates$lga_lon[1],  # Add LGA longitude\n    hover_text = paste(\n      \"Destination:\", name,  # Full airport name\n      \"&lt;br&gt;Dominant Airline:\", dominant_airline_name,  # Dominant airline name\n      \"&lt;br&gt;Avg Flights/Day (All Airlines):\", avg_flights_per_day  # Average flights per day\n    )\n  )\n\n# Step 5: Plot the map without labels for airport codes\nmap &lt;- ggplot() +\n  borders(\"state\", colour = \"grey80\", fill = \"grey95\") +  # Light grey land and subtle borders\n  geom_point(\n    data = flights_map_data,\n    aes(\n      x = lon, y = lat, color = dominant_airline_name, size = total_flights,\n      text = hover_text  # Explicitly set hover text for Plotly\n    ),\n    alpha = 0.8  # Slight transparency for points\n  ) +\n  geom_segment(\n    data = flights_map_data,\n    aes(\n      x = lga_lon, y = lga_lat, xend = lon, yend = lat,\n      color = dominant_airline_name,\n      text = hover_text  # Explicitly set hover text for Plotly\n    ),\n    size = 0.5, alpha = 0.6  # Softer and thinner lines\n  ) +\n  scale_color_viridis_d(name = \"Dominant Airline\", option = \"D\") +  # Use the viridis palette\n  scale_size_continuous(name = \"Total Flights\", range = c(2, 6)) +  # Scale point sizes\n  coord_cartesian(xlim = c(-125, -66), ylim = c(24, 50)) +  # Continental US\n  labs(\n    title = \"Flight Connections from NY to Destinations\",\n    subtitle = \"Color-coded by Dominant Airline Name | Point size proportional to total flights\",\n    x = \"Longitude\",\n    y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 14) +  # Modern and clean theme\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, color = \"black\"),\n    plot.subtitle = element_text(size = 12, margin = margin(b = 10), color = \"black\"),\n    legend.position = \"right\",\n    legend.text = element_text(color = \"black\"),\n    legend.title = element_text(color = \"black\"),\n    panel.grid.major = element_blank(),  # Remove major gridlines\n    panel.grid.minor = element_blank(),  # Remove minor gridlines\n    panel.background = element_rect(fill = \"white\", colour = NA),  # White background\n    plot.background = element_rect(fill = \"white\", color = NA),  # Match overall plot background\n    panel.border = element_blank(),\n    axis.text = element_text(color = \"black\"),\n    axis.title = element_text(color = \"black\"),\n    axis.ticks = element_blank()\n  )\n\nWarning in geom_point(data = flights_map_data, aes(x = lon, y = lat, color =\ndominant_airline_name, : Ignoring unknown aesthetics: text\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in geom_segment(data = flights_map_data, aes(x = lga_lon, y = lga_lat,\n: Ignoring unknown aesthetics: text\n\n# Step 6: Convert the ggplot to Plotly with explicit hover text\ninteractive_map &lt;- ggplotly(\n  map,\n  tooltip = \"text\"  # Explicitly map the hover text field\n)\n\n# Step 7: Display the interactive map\ninteractive_map\n\n\n\n\n\n\n# Step 1: Filter flights and rename columns for clarity\nflights_subset &lt;- flights %&gt;%\n  filter(\n    !dest %in% c(\"HNL\", \"ANC\")  # Exclude Honolulu and Anchorage\n  ) %&gt;%\n  left_join(airports, by = c(\"origin\" = \"faa\")) %&gt;%\n  rename(origin_name = name)  # Rename origin airport name to avoid conflicts\n\n# Step 2: Summarize flights by destination and origin airport\nflights_summary &lt;- flights_subset %&gt;%\n  group_by(dest, origin) %&gt;%\n  summarise(total_flights = n(), .groups = \"drop\") %&gt;%\n  group_by(dest) %&gt;%\n  mutate(\n    dominant_origin = origin[which.max(total_flights)],  # Determine dominant origin airport\n    total_flights = sum(total_flights),  # Total flights to the destination\n    avg_flights_per_day = round(total_flights / 365, 1)  # Average flights per day (1 decimal place)\n  ) %&gt;%\n  filter(total_flights &gt;= 365)  # Keep destinations with at least 365 flights\n\n# Step 3: Add geolocation data for destinations using the airports dataset\nflights_map_data &lt;- flights_summary %&gt;%\n  left_join(airports, by = c(\"dest\" = \"faa\")) %&gt;%\n  left_join(airports, by = c(\"dominant_origin\" = \"faa\"), suffix = c(\"_dest\", \"_origin\"))\n\n# Step 4: Add LGA coordinates as the neutral origin point\nlga_coordinates &lt;- airports %&gt;%\n  filter(faa == \"LGA\") %&gt;%\n  select(lat, lon) %&gt;%\n  rename(lga_lat = lat, lga_lon = lon)\n\n# Add hover text and LGA coordinates to the data\nflights_map_data &lt;- flights_map_data %&gt;%\n  mutate(\n    lga_lat = lga_coordinates$lga_lat[1],  # Add LGA latitude\n    lga_lon = lga_coordinates$lga_lon[1],  # Add LGA longitude\n    hover_text = paste(\n      \"Destination:\", name_dest,  # Full destination airport name\n      \"&lt;br&gt;Dominant Origin Airport:\", name_origin,  # Dominant origin airport name\n      \"&lt;br&gt;Avg Flights/Day (All Origins):\", avg_flights_per_day  # Average flights per day\n    )\n  )\n\n# Step 5: Plot the map based on origin airports\nmap &lt;- ggplot() +\n  borders(\"state\", colour = \"grey80\", fill = \"grey95\") +  # Light grey land and subtle borders\n  geom_point(\n    data = flights_map_data,\n    aes(\n      x = lon_dest, y = lat_dest, color = name_origin, size = total_flights,\n      text = hover_text  # Explicitly set hover text for Plotly\n    ),\n    alpha = 0.8  # Slight transparency for points\n  ) +\n  geom_segment(\n    data = flights_map_data,\n    aes(\n      x = lga_lon, y = lga_lat, xend = lon_dest, yend = lat_dest,\n      color = name_origin,\n      text = hover_text  # Explicitly set hover text for Plotly\n    ),\n    size = 0.5, alpha = 0.6  # Softer and thinner lines\n  ) +\n  scale_color_viridis_d(name = \"Dominant Origin Airport\", option = \"D\") +  # Use the viridis palette\n  scale_size_continuous(name = \"Total Flights\", range = c(2, 6)) +  # Scale point sizes\n  coord_cartesian(xlim = c(-125, -66), ylim = c(24, 50)) +  # Continental US\n  labs(\n    title = \"Flight Connections from NY to Destinations\",\n    subtitle = \"Color-coded by Dominant Origin Airport | Point size proportional to total flights\",\n    x = \"Longitude\",\n    y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 14) +  # Modern and clean theme\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, color = \"black\"),\n    plot.subtitle = element_text(size = 12, margin = margin(b = 10), color = \"black\"),\n    legend.position = \"right\",\n    legend.text = element_text(color = \"black\"),\n    legend.title = element_text(color = \"black\"),\n    panel.grid.major = element_blank(),  # Remove major gridlines\n    panel.grid.minor = element_blank(),  # Remove minor gridlines\n    panel.background = element_rect(fill = \"white\", colour = NA),  # White background\n    plot.background = element_rect(fill = \"white\", color = NA),  # Match overall plot background\n    panel.border = element_blank(),\n    axis.text = element_text(color = \"black\"),\n    axis.title = element_text(color = \"black\"),\n    axis.ticks = element_blank()\n  )\n\nWarning in geom_point(data = flights_map_data, aes(x = lon_dest, y = lat_dest,\n: Ignoring unknown aesthetics: text\n\n\nWarning in geom_segment(data = flights_map_data, aes(x = lga_lon, y = lga_lat,\n: Ignoring unknown aesthetics: text\n\n# Step 6: Convert the ggplot to Plotly with explicit hover text\ninteractive_map &lt;- ggplotly(\n  map,\n  tooltip = \"text\"  # Explicitly map the hover text field\n)\n\n# Step 7: Display the interactive map\ninteractive_map"
  },
  {
    "objectID": "posts/nyflights13/Nycflights13.html",
    "href": "posts/nyflights13/Nycflights13.html",
    "title": "nycflights13",
    "section": "",
    "text": "Using the nycflights13 dataset, this analysis examines flight patterns from New York’s three major airports: JFK, LGA, and EWR. Visualizations include pie charts showing airline proportions, line charts of flights by hour, and interactive maps of routes, providing insights into departure trends and airline operations."
  },
  {
    "objectID": "posts/berlinmar/berlinmar.html",
    "href": "posts/berlinmar/berlinmar.html",
    "title": "Berlin Marathon 2019",
    "section": "",
    "text": "This analysis explores the 2019 Berlin Marathon data."
  },
  {
    "objectID": "posts/ggmaps/ggmaps_web.html",
    "href": "posts/ggmaps/ggmaps_web.html",
    "title": "Public Transport Transit Time Analysis",
    "section": "",
    "text": "This report showcases transit time analyses for various cities around the world. The visualizations highlight the travel times to key central locations (e.g., main train stations) from surrounding areas using public transit at 8:00AM on a workday. These analyses can provide insights into urban transit accessibility."
  },
  {
    "objectID": "posts/ggmaps/ggmaps_web.html#sydney-syd",
    "href": "posts/ggmaps/ggmaps_web.html#sydney-syd",
    "title": "Public Transport Transit Time Analysis",
    "section": "Sydney (SYD)",
    "text": "Sydney (SYD)"
  },
  {
    "objectID": "posts/ggmaps/ggmaps_web.html#melbourne-mel",
    "href": "posts/ggmaps/ggmaps_web.html#melbourne-mel",
    "title": "Public Transport Transit Time Analysis",
    "section": "Melbourne (MEL)",
    "text": "Melbourne (MEL)"
  },
  {
    "objectID": "posts/ggmaps/ggmaps_web.html#adelaide-adl",
    "href": "posts/ggmaps/ggmaps_web.html#adelaide-adl",
    "title": "Public Transport Transit Time Analysis",
    "section": "Adelaide (ADL)",
    "text": "Adelaide (ADL)"
  },
  {
    "objectID": "posts/ggmaps/ggmaps_web.html#jakarta-jkt",
    "href": "posts/ggmaps/ggmaps_web.html#jakarta-jkt",
    "title": "Public Transport Transit Time Analysis",
    "section": "Jakarta (JKT)",
    "text": "Jakarta (JKT)"
  },
  {
    "objectID": "posts/ggmaps/ggmaps_web.html#new-york-city-nyc",
    "href": "posts/ggmaps/ggmaps_web.html#new-york-city-nyc",
    "title": "Public Transport Transit Time Analysis",
    "section": "New York City (NYC)",
    "text": "New York City (NYC)"
  },
  {
    "objectID": "posts/berlinmar17/berlinmar18.html",
    "href": "posts/berlinmar17/berlinmar18.html",
    "title": "Berlin Marathon 2018",
    "section": "",
    "text": "This analysis explores the 2018 Berlin Marathon data."
  },
  {
    "objectID": "posts/Fifa rank/fifa_rank.html",
    "href": "posts/Fifa rank/fifa_rank.html",
    "title": "FIFA Ranking by GDP per Capita",
    "section": "",
    "text": "This analysis looks at the relationship between FIFA rankings, GDP per capita, and population size in 2020. The data is divided into rank groups, from the top 10 teams to those ranked 41-50. A bubble chart is created to show how FIFA rankings relate to a country’s GDP per capita, with the bubble size representing the country’s population. The chart helps visualize the connection between football rankings, economic status, and population. A bar chart is also used to display the distribution of population across different FIFA rank groups, showing how population sizes vary by ranking. Together, these charts provide a clear picture of how football success, economy, and population are linked.\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter"
  },
  {
    "objectID": "posts/Fifa rank/fifa_rank.html#quarto",
    "href": "posts/Fifa rank/fifa_rank.html#quarto",
    "title": "FIFA Ranking by GDP per Capita",
    "section": "",
    "text": "No trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter"
  },
  {
    "objectID": "posts/movies/Movie.html",
    "href": "posts/movies/Movie.html",
    "title": "IMDB Ratings - Indonesian Movies",
    "section": "",
    "text": "Director Name\nMovie Count\nAverage Rating\nAverage Vote Count\n\n\n\n\nAngga Dwimas Sasongko\n8\n6.8\n966.0\n\n\nMonty Tiwa\n6\n6.6\n155.7\n\n\nJoko Anwar\n7\n6.5\n4143.0\n\n\nUpi Avianto\n6\n6.5\n562.6\n\n\nAwi Suryadi\n7\n6.4\n643.7\n\n\nHanung Bramantyo\n14\n6.3\n367.1\n\n\nRudy Soedjarwo\n6\n6.2\n433.6\n\n\nGuntur Soeharjanto\n7\n6.1\n275.3\n\n\nRizal Mantovani\n9\n5.7\n235.4\n\n\nAnggy Umbara\n11\n5.4\n375.8\n\n\nHadrah Daeng Ratu\n6\n5.4\n664.0\n\n\nHelfi C.H. Kardit\n9\n5.2\n96.7"
  },
  {
    "objectID": "posts/Pilpres V Pileg/PilpresvPileg.html",
    "href": "posts/Pilpres V Pileg/PilpresvPileg.html",
    "title": "2024 Pilpres vs Pileg Party Coalition Vote Percentages",
    "section": "",
    "text": "This analysis compares the 2024 presidential (Pilpres) election results for Anies Baswedan, Prabowo Subianto, and Ganjar Pranowo with the total legislative (Pileg) vote for the parties in their supporting coalitions. Scatter plots show how each candidate’s Pilpres vote percentage relates to the total Pileg vote percentage for their coalition. The plots include lines to highlight where the results match or differ. The analysis also calculates the difference between Pilpres and Pileg results, focusing on regions with the largest gaps. Interactive visualizations allow readers to explore these differences and see how Pilpres support aligns with party support in the legislative election.\n\n\n\nCoalitions and their Supporting Parties for the 2024 Indonesian Presidential Election\n\n\n\n\n\n\nCoalition\nParties\n\n\n\n\nAnies Baswedan’s Coalition (Change Coalition)\nNasdem Party, Democratic Party (Partai Demokrat), Prosperous Justice Party (PKS)\n\n\nPrabowo Subianto’s Coalition (Great Indonesia Coalition)\nGerindra Party, Golkar Party, National Mandate Party (PAN), United Development Party (PPP), Gelora Party, Berkarya Party\n\n\nGanjar Pranowo’s Coalition (PDI-P and Allies)\nIndonesian Democratic Party of Struggle (PDI-P), National Awakening Party (PKB), Indonesian Solidarity Party (PSI), Hanura Party, Perindo Party, PBB (Crescent Star Party)"
  },
  {
    "objectID": "posts/Air Pollution/report.html",
    "href": "posts/Air Pollution/report.html",
    "title": "Which Australian city has the cleanest air?",
    "section": "",
    "text": "knitr::include_graphics(\"pollution.jpg\")"
  },
  {
    "objectID": "posts/Air Pollution/report.html#data-description",
    "href": "posts/Air Pollution/report.html#data-description",
    "title": "Which Australian city has the cleanest air?",
    "section": "Data description",
    "text": "Data description\nData Collection:\n\nThe data was collected using the airpurifyr package, which retrieves air quality measurements from the OpenAQ API, which is an open-source platform that aggregates air quality data from government and research organizations worldwide.\nData is collected via sensors located in various cities and locations in Australia. The get_measurements_for_location() function is used to pull data based on city, location, and time range.\n\nVariables:\n\nlocation_id: Identifier for the location of the sensor.\nlocation: Name of the sensor’s location.\nparameter: Type of air quality measurement (eg, PM2.5, NO2).\nvalue: The pollutant concentration.\ndate_utc: Timestamp when the measurement was recorded.\nunit: Measurement unit (typically µg/m³).\nlat: Latitude of the sensor.\nlong: Longitude of the sensor.\ncountry: Country code (e.g., AU for Australia)."
  },
  {
    "objectID": "posts/Air Pollution/report.html#initial-data-analysis-exploratory-data-analysis",
    "href": "posts/Air Pollution/report.html#initial-data-analysis-exploratory-data-analysis",
    "title": "Which Australian city has the cleanest air?",
    "section": "Initial data analysis & Exploratory data analysis",
    "text": "Initial data analysis & Exploratory data analysis\n\nChecking the data type\nBelow is a glimpse at the dataset.\n\n\ntibble [44,522 × 14] (S3: tbl_df/tbl/data.frame)\n $ location_id                : int [1:44522] 5521 5521 5521 5521 5521 5521 5521 5521 5521 5521 ...\n $ location                   : chr [1:44522] \"Rocklea\" \"Rocklea\" \"Rocklea\" \"Rocklea\" ...\n $ parameter                  : chr [1:44522] \"pm25\" \"pm25\" \"pm25\" \"pm25\" ...\n $ value                      : num [1:44522] 20.6 20.7 20.7 20.4 20.4 20 19.5 19.2 18.9 18.5 ...\n $ date_utc                   : POSIXct[1:44522], format: \"2024-08-31 00:00:00\" ...\n $ unit                       : chr [1:44522] \"µg/m³\" \"µg/m³\" \"µg/m³\" \"µg/m³\" ...\n $ lat                        : num [1:44522] -27.5 -27.5 -27.5 -27.5 -27.5 ...\n $ long                       : num [1:44522] 153 153 153 153 153 ...\n $ country                    : chr [1:44522] \"AU\" \"AU\" \"AU\" \"AU\" ...\n $ City                       : chr [1:44522] \"Brisbane\" \"Brisbane\" \"Brisbane\" \"Brisbane\" ...\n $ State                      : chr [1:44522] \"Queensland\" \"Queensland\" \"Queensland\" \"Queensland\" ...\n $ Population                 : num [1:44522] 2545882 2545882 2545882 2545882 2545882 ...\n $ Central_Station_Coordinates: chr [1:44522] \"-27.467, 153.017\" \"-27.467, 153.017\" \"-27.467, 153.017\" \"-27.467, 153.017\" ...\n $ Air_Station_Count          : num [1:44522] 5 5 5 5 5 5 5 5 5 5 ...\n\n\nAfter examining the structure of the dataset and the data types of its variable, we can infer that the data types are appropriately assigned based on the nature of each variable. For example, timestamps are appropriately stored as POSIXct for time-based analysis, and numerical values for pollutants are stored as numeric.\n\n\nAggregate by hours:\nBelow is a glimpse at the dataset.\n\n\n# A tibble: 6 × 14\n  location_id location parameter value date_utc           \n        &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;dttm&gt;             \n1        5521 Rocklea  pm25       20.6 2024-08-31 00:00:00\n2        5521 Rocklea  pm25       20.7 2024-08-30 23:00:00\n3        5521 Rocklea  pm25       20.7 2024-08-30 22:00:00\n4        5521 Rocklea  pm25       20.4 2024-08-30 21:00:00\n5        5521 Rocklea  pm25       20.4 2024-08-30 20:00:00\n6        5521 Rocklea  pm25       20   2024-08-30 19:00:00\n# ℹ 9 more variables: unit &lt;chr&gt;, lat &lt;dbl&gt;, long &lt;dbl&gt;,\n#   country &lt;chr&gt;, City &lt;chr&gt;, State &lt;chr&gt;,\n#   Population &lt;dbl&gt;, Central_Station_Coordinates &lt;chr&gt;,\n#   Air_Station_Count &lt;dbl&gt;\n\n\nWe can see that the values of the parameters are recorded hourly, which means it is already aggregated by hour. However, some time intervals are not recorded, therefore we will add in rows with observations with the missing hours and the values being NA, for further analysis.\nNext, we will check the total numbers of time stamps records for all the parameters across the locations. The recorded data is within 60 days, which means 1440 (hourly) records for each parameter of each location. The below code will show how many records of each parameters across all locations.\n\n\n\n\n\nparameter\nlocation\ntimestamp_count\nrecords_proportion\n\n\n\n\nco\nAlphington\n1341\n93\n\n\nno2\nAlphington\n1340\n93\n\n\nno2\nAltona North\n1351\n94\n\n\no3\nAlphington\n1343\n93\n\n\no3\nCannon Hill\n719\n50\n\n\no3\nRocklea\n719\n50\n\n\npm10\nSubiaco\n1392\n97\n\n\npm10\nAlphington\n1337\n93\n\n\npm10\nAnzac Memorial\n1398\n97\n\n\npm10\nBrisbane CBD\n719\n50\n\n\npm10\nBrooklyn\n1417\n98\n\n\npm10\nCBD West\n1398\n97\n\n\npm10\nCannon Hill\n719\n50\n\n\npm10\nFootscray\n312\n22\n\n\npm10\nKingsville\n1316\n91\n\n\npm10\nLuna Lewisham\n1393\n97\n\n\npm10\nRocklea\n719\n50\n\n\npm10\nSouth Brisbane\n719\n50\n\n\npm10\nSydney, Australia\n1398\n97\n\n\npm10\nWoolloongabba\n719\n50\n\n\npm25\nSubiaco\n1392\n97\n\n\npm25\nAlphington\n1411\n98\n\n\npm25\nAltona North\n1403\n97\n\n\npm25\nAnzac Memorial\n1398\n97\n\n\npm25\nBrisbane CBD\n719\n50\n\n\npm25\nBrooklyn\n1357\n94\n\n\npm25\nCBD West\n1398\n97\n\n\npm25\nCannon Hill\n719\n50\n\n\npm25\nFootscray\n1208\n84\n\n\npm25\nKingsville\n1307\n91\n\n\npm25\nLuna Lewisham\n1393\n97\n\n\npm25\nMelbourne CBD\n1414\n98\n\n\npm25\nRocklea\n719\n50\n\n\npm25\nSouth Brisbane\n719\n50\n\n\npm25\nSpotswood\n1387\n96\n\n\npm25\nSydney, Australia\n1398\n97\n\n\npm25\nWoolloongabba\n719\n50\n\n\nso2\nAlphington\n1341\n93\n\n\nso2\nAltona North\n1351\n94\n\n\n\n\n\nFrom the table above, we can infer that most of the parameters are not complete with the hourly time stamps, and parameters pm10 and pm25 are recorded the most within the data set, whereas the other pollutants show significant low records across locations, leading to lower completeness and bias when comparing pollutants level across different areas.\n\n\nChecking the missingness and outliers\nWe will use the vis_miss() function from the visdat package to visualize the missingness of the dataset across variables, after completing the dataset with missing time stamps. We can see that in about 4% of the time, the data is not recorded.\n\n\n\n\n\n\n\n\n\nTo explore further the coverage of pollutants across cities, we will visualize the observation records on a time series plot to see which parameters are recorded across different cities and time intervals.\n\n\n\n\n\n\n\n\n\nSO2, NO2, and CO appear to have less coverage across all locations, whereas PM25 and PM10 are recorded more consistently across the majority of locations, making them suitable for further analysis without the need for significant imputation or data handling. Besides, Brisbane only have data recorded from 1st Aug to 1st Sep, suggesting careful handling in further analysis.\nData distribution:\nWe will use box plot to have a glimpse at the distributions of the parameters across locations.\n\n\n\n\n\n\n\n\n\nFrom the plot above, we can infer several key observations:\n\nCO, NO2: There are multiple high outliers, which may represent extreme pollution events or possible sensor anomalies.\nO3, PM10, and PM25: We identified extreme negative outliers for these pollutants, which are likely errors in the dataset.\nSO2: Some high outliers were observed, likely due to limited records or inconsistencies in the dataset.\n\nTo ensure our analysis focuses on typical air quality levels, we remove outliers—extreme values that could distort the results. The lower and upper bounds were determined using the interquartile range (IQR), where any values below 1.5 times the IQR from the lower quartile or above 1.5 times the IQR from the upper quartile were considered outliers.\nBy filtering out these outliers, we can focus on more accurate, typical pollutant readings, improving the quality of our analysis."
  },
  {
    "objectID": "posts/Air Pollution/report.html#results",
    "href": "posts/Air Pollution/report.html#results",
    "title": "Which Australian city has the cleanest air?",
    "section": "Results",
    "text": "Results\nAs mentioned above, we focused on two key pollutants, PM10 and PM2.5, from the air quality data. For each city, we calculated the median value of these pollutants based on all the sensors that measured them. This gave us a representative value of air quality in each city. Finally, we organized the data so that each city has its own row, with separate columns showing the median levels of PM10 and PM2.5.\n\n\n\n\n\nCity\npm10\npm25\n\n\n\n\nAdelaide\n2.6\n2.3\n\n\nBrisbane\n16.8\n7.1\n\n\nMelbourne\n13.3\n3.2\n\n\nPerth\n2.2\n2.1\n\n\nSydney\n3.3\n3.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe bar chart above compares the concentration of two key pollutants, PM10 (in orange) and PM2.5 (in blue), across five Australian cities: Adelaide, Brisbane, Melbourne, Perth, and Sydney. As seen in the chart, Brisbane and Melbourne have significantly higher concentrations of both pollutants compared to the other cities, with Brisbane showing the highest levels for both PM10 and PM2.5. In contrast, Adelaide and Perth have much lower concentrations, while Sydney falls in between.\nThis data prompts the need to define what we mean by “clean air” for the purpose of this analysis. In the sections below, I will discuss how we can establish thresholds or criteria to classify air quality based on the observed pollutant levels. This will help in determining which cities have cleaner air relative to others based on the levels of PM10 and PM2.5.\nBased on the comparison of PM10 and PM2.5 levels across the cities, we decided to define “clean air” by taking the halfway point between the median concentrations of these two pollutants. This threshold will help us classify cities with better air quality as those falling below the midpoint and more polluted cities as those above it.\nUsing this criterion, we create a new plot to visualize which cities have cleaner air and which do not, based on their pollutant levels relative to this defined midpoint. This approach will allow us to make clearer distinctions between cities regarding their air quality.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCity\nPM10 (Median)\nPM25 (Median)\nMidway Point\n\n\n\n\nPerth\n2.2\n2.1\n2.1\n\n\nAdelaide\n2.6\n2.3\n2.5\n\n\nSydney\n3.3\n3.1\n3.2\n\n\nMelbourne\n13.3\n3.2\n8.3\n\n\nBrisbane\n16.8\n7.1\n11.9\n\n\n\n\n\n\n\n\n\nBased on the analysis, we can conclude that Perth has the cleanest air using the halfway point between the median PM10 and median PM2.5 values, narrowly surpassing Adelaide. However, it is important to note that both Adelaide and Perth have only one sensor each, which may introduce bias. While this is the best data available, future studies would benefit from each city having a similar number of sensors to ensure more accurate comparisons."
  },
  {
    "objectID": "posts/Air Pollution/report.html#references",
    "href": "posts/Air Pollution/report.html#references",
    "title": "Which Australian city has the cleanest air?",
    "section": "References",
    "text": "References\n\n\n\nWickham, H. (2019). *tidyverse: Easily install and load the 'tidyverse'*. R package version 1.3.0. https://CRAN.R-project.org/package=tidyverse\n\nWickham, H., & Bryan, J. (2019). *readxl: Read excel files*. R package version 1.3.1. https://CRAN.R-project.org/package=readxl\n\nTierney, N., & Cook, D. (2022). *visdat: Visualising whole data frames*. R package version 0.5.3. https://CRAN.R-project.org/package=visdat\n\nTierney, N., & Cook, D. (2022). *naniar: Data structures, summaries, and visualisations for missing data*. R package version 0.6.1. https://CRAN.R-project.org/package=naniar\n\nMoritz, S. (2022). *imputeTS: Time series missing value imputation*. R package version 3.2. https://CRAN.R-project.org/package=imputeTS\n\nWickham, H. (2019). *rvest: Easily harvest (scrape) web data*. R package version 0.3.5. https://CRAN.R-project.org/package=rvest\n\nWickham, H. (2022). *conflicted: An alternative conflict resolution strategy*. R package version 1.0.4. https://CRAN.R-project.org/package=conflicted\n\nNumbats. (n.d.). *airpurifyr: Air pollution modeling for Australia*. Retrieved from https://numbats.github.io/airpurifyr/\n\nWickham, H. (2016). *ggplot2: Elegant graphics for data analysis*. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\nKahle, D., & Wickham, H. (2013). *ggmap: Spatial visualization with ggplot2*. The R Journal, 5(1), 144-161. https://journal.r-project.org/archive/2013-1/kahle-wickham.pdf\n\nSievert, C. (2020). *Interactive web-based data visualization with R, plotly, and shiny*. Chapman and Hall/CRC. https://plotly-r.com\n\nHijmans, R. J. (2019). *geosphere: Spherical trigonometry*. R package version 1.5-10. https://CRAN.R-project.org/package=geosphere\n\nZhu, H. (2021). *kableExtra: Construct complex table with 'kable' and pipe syntax*. R package version 1.3.4. https://CRAN.R-project.org/package=kableExtra\n\nOpenAI. (2023). *ChatGPT (October 2023 version) [Large language model]*. https://chat.openai.com"
  }
]